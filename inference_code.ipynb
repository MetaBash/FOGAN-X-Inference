{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27f50ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy==1.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564dc5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4008d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms \n",
    "import time\n",
    "from torchvision.utils import save_image\n",
    "from generator import GeneratorResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb829a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, use_bias):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        conv_block = []\n",
    "        conv_block += [nn.ReflectionPad2d(1),\n",
    "                       nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=0, bias=use_bias),\n",
    "                       nn.InstanceNorm2d(dim),\n",
    "                       nn.ReLU(True)]\n",
    "\n",
    "        conv_block += [nn.ReflectionPad2d(1),\n",
    "                       nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=0, bias=use_bias),\n",
    "                       nn.InstanceNorm2d(dim)]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResnetAdaILNBlock(nn.Module):\n",
    "    def __init__(self, dim, use_bias):\n",
    "        super(ResnetAdaILNBlock, self).__init__()\n",
    "        self.pad1 = nn.ReflectionPad2d(1)\n",
    "        self.conv1 = nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=0, bias=use_bias)\n",
    "        self.norm1 = adaILN(dim)\n",
    "        self.relu1 = nn.ReLU(True)\n",
    "\n",
    "        self.pad2 = nn.ReflectionPad2d(1)\n",
    "        self.conv2 = nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=0, bias=use_bias)\n",
    "        self.norm2 = adaILN(dim)\n",
    "\n",
    "    def forward(self, x, gamma, beta):\n",
    "        out = self.pad1(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.norm1(out, gamma, beta)\n",
    "        out = self.relu1(out)\n",
    "        out = self.pad2(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out, gamma, beta)\n",
    "\n",
    "        return out + x\n",
    "\n",
    "\n",
    "class adaILN(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5):\n",
    "        super(adaILN, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.rho = Parameter(torch.Tensor(1, num_features, 1, 1))\n",
    "        self.rho.data.fill_(0.9)\n",
    "\n",
    "    def forward(self, input, gamma, beta):\n",
    "        in_mean, in_var = torch.mean(input, dim=[2, 3], keepdim=True), torch.var(input, dim=[2, 3], keepdim=True)\n",
    "        out_in = (input - in_mean) / torch.sqrt(in_var + self.eps)\n",
    "        ln_mean, ln_var = torch.mean(input, dim=[1, 2, 3], keepdim=True), torch.var(input, dim=[1, 2, 3], keepdim=True)\n",
    "        out_ln = (input - ln_mean) / torch.sqrt(ln_var + self.eps)\n",
    "        out = self.rho.expand(input.shape[0], -1, -1, -1) * out_in + (1-self.rho.expand(input.shape[0], -1, -1, -1)) * out_ln\n",
    "        out = out * gamma.unsqueeze(2).unsqueeze(3) + beta.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ILN(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5):\n",
    "        super(ILN, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.rho = Parameter(torch.Tensor(1, num_features, 1, 1))\n",
    "        self.gamma = Parameter(torch.Tensor(1, num_features, 1, 1))\n",
    "        self.beta = Parameter(torch.Tensor(1, num_features, 1, 1))\n",
    "        self.rho.data.fill_(0.0)\n",
    "        self.gamma.data.fill_(1.0)\n",
    "        self.beta.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        in_mean, in_var = torch.mean(input, dim=[2, 3], keepdim=True), torch.var(input, dim=[2, 3], keepdim=True)\n",
    "        out_in = (input - in_mean) / torch.sqrt(in_var + self.eps)\n",
    "        ln_mean, ln_var = torch.mean(input, dim=[1, 2, 3], keepdim=True), torch.var(input, dim=[1, 2, 3], keepdim=True)\n",
    "        out_ln = (input - ln_mean) / torch.sqrt(ln_var + self.eps)\n",
    "        out = self.rho.expand(input.shape[0], -1, -1, -1) * out_in + (1-self.rho.expand(input.shape[0], -1, -1, -1)) * out_ln\n",
    "        out = out * self.gamma.expand(input.shape[0], -1, -1, -1) + self.beta.expand(input.shape[0], -1, -1, -1)\n",
    "\n",
    "        return out\n",
    "\n",
    "class GeneratorResNet(nn.Module):\n",
    "    def __init__(self, input_nc=3, output_nc=3, ngf=64, n_blocks=6, img_size=256, light=False):\n",
    "        assert(n_blocks >= 0)\n",
    "        super(GeneratorResNet, self).__init__()\n",
    "        self.input_nc = input_nc\n",
    "        self.output_nc = output_nc\n",
    "        self.ngf = ngf\n",
    "        self.n_blocks = n_blocks\n",
    "        self.img_size = img_size\n",
    "        self.light = light\n",
    "        DownBlock = []\n",
    "        DownBlock += [nn.ReflectionPad2d(3),\n",
    "                      nn.Conv2d(input_nc, ngf, kernel_size=7, stride=1, padding=0, bias=False),\n",
    "                      nn.InstanceNorm2d(ngf),\n",
    "                      nn.ReLU(True)]\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**i\n",
    "            DownBlock += [nn.ReflectionPad2d(1),\n",
    "                          nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=0, bias=False),\n",
    "                          nn.InstanceNorm2d(ngf * mult * 2),\n",
    "                          nn.ReLU(True)]\n",
    "        mult = 2**n_downsampling\n",
    "        for i in range(n_blocks):\n",
    "            DownBlock += [ResnetBlock(ngf * mult, use_bias=False)]\n",
    "\n",
    "        self.gap_fc = nn.Linear(ngf * mult, 1, bias=False)\n",
    "        self.gmp_fc = nn.Linear(ngf * mult, 1, bias=False)\n",
    "        self.conv1x1 = nn.Conv2d(ngf * mult * 2, ngf * mult, kernel_size=1, stride=1, bias=True)\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "        if self.light:#64\n",
    "            FC = [nn.Linear(ngf * mult, ngf * mult, bias=False),\n",
    "                  nn.ReLU(True),\n",
    "                  nn.Linear(ngf * mult, ngf * mult, bias=False),\n",
    "                  nn.ReLU(True)]\n",
    "        else:\n",
    "            FC = [nn.Linear( ngf * mult * (img_size // mult) * (img_size // mult), ngf * mult, bias=False),\n",
    "                  nn.ReLU(True),\n",
    "                  nn.Linear(ngf * mult, ngf * mult, bias=False),\n",
    "                  nn.ReLU(True)]\n",
    "        self.gamma = nn.Linear(ngf * mult, ngf * mult, bias=False)\n",
    "        self.beta = nn.Linear(ngf * mult, ngf * mult, bias=False)\n",
    "\n",
    "        for i in range(n_blocks):\n",
    "            setattr(self, 'UpBlock1_' + str(i+1), ResnetAdaILNBlock(ngf * mult, use_bias=False))\n",
    "\n",
    "        UpBlock2 = []\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**(n_downsampling - i)\n",
    "            UpBlock2 += [nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                         nn.ReflectionPad2d(1),\n",
    "                         nn.Conv2d(ngf * mult, int(ngf * mult / 2), kernel_size=3, stride=1, padding=0, bias=False),\n",
    "                         ILN(int(ngf * mult / 2)),\n",
    "                         nn.ReLU(True)]\n",
    "        UpBlock2 += [nn.ReflectionPad2d(3),\n",
    "                     nn.Conv2d(ngf, output_nc, kernel_size=7, stride=1, padding=0, bias=False)]\n",
    "\n",
    "        self.DownBlock = nn.Sequential(*DownBlock)\n",
    "        self.FC = nn.Sequential(*FC)\n",
    "        self.UpBlock2 = nn.Sequential(*UpBlock2)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.DownBlock(input)\n",
    "\n",
    "        gap = torch.nn.functional.adaptive_avg_pool2d(x, 1)\n",
    "        gap_logit = self.gap_fc(gap.view(x.shape[0], -1))\n",
    "        gap_weight = list(self.gap_fc.parameters())[0]\n",
    "        gap = x * gap_weight.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "        gmp = torch.nn.functional.adaptive_max_pool2d(x, 1)\n",
    "        gmp_logit = self.gmp_fc(gmp.view(x.shape[0], -1))\n",
    "        gmp_weight = list(self.gmp_fc.parameters())[0]\n",
    "        gmp = x * gmp_weight.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "        cam_logit = torch.cat([gap_logit, gmp_logit], 1)\n",
    "        x = torch.cat([gap, gmp], 1)\n",
    "        x = self.relu(self.conv1x1(x))\n",
    "\n",
    "        heatmap = torch.sum(x, dim=1, keepdim=True)\n",
    "\n",
    "        if self.light:\n",
    "            x_ = torch.nn.functional.adaptive_avg_pool2d(x, 1)\n",
    "            x_ = self.FC(x_.view(x_.shape[0], -1))\n",
    "        else:\n",
    "            x_ = self.FC(x.view(x.shape[0], -1))\n",
    "        gamma, beta = self.gamma(x_), self.beta(x_)\n",
    "\n",
    "\n",
    "        for i in range(self.n_blocks):\n",
    "            x = getattr(self, 'UpBlock1_' + str(i+1))(x, gamma, beta)\n",
    "        out = (self.UpBlock2(x)+input).tanh()\n",
    "\n",
    "        return out, cam_logit, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c753fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_weights = torch.load('./saved_models/generator.pt', map_location=torch.device('cpu') )\n",
    "\n",
    "model = GeneratorResNet(input_nc=3, output_nc=3, ngf=64, n_blocks=4, img_size=512, light=True)\n",
    "model.load_state_dict( loaded_weights )\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# loading the video \n",
    "cam = cv2.VideoCapture(\"    \")\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor() \n",
    "]) \n",
    "\n",
    "start_time = time.time()\n",
    "img = Image.open(\"./test_input/1.jpg\").convert('RGB')  # Convert to RGB if not already\n",
    "img_tensor = transform(img).unsqueeze(0)\n",
    "output = model( img_tensor.float() ) \n",
    "save_image(output[0], f\"val_outputs/out.png\", normalize=True)\n",
    "end_time = time.time()\n",
    "\n",
    "print( \"Inference time - \", (end_time - start_time ) ) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Root",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
